** Gauss-Newton and Conjugate-Gradient optimization **

This code implements a Gauss-Newton 
optimization of objective functions that can
be iteratively approximated by quadratics.
This approach is particularly appropriate
for least-squares inversions of moderately
non-linear transforms.  You will also find
code for conjugate-gradient and line-search
optimizations.  

Get documentation of the algorithm here:
[[../../papers/inv/]] [[../../papers/inv.pdf]] [[../../papers/inv.ps.gz]] 

See the java documentation in the 
documentation subdirectory [[documentation]].

All files with ``main'' contain test code.
You can run all tests with ``Test.main().''

See an older C++ version [[../conjugate_gradients/]]

Several papers describe ways to use this code:
  [[../../papers/regularization.pdf]] [[../../papers/regularization/]]
  [[../../papers/neural.pdf]] [[../../papers/neural/]]
  [[../../papers/rmsinv.pdf]] [[../../papers/rmsinv/]]

From http://billharlan.com/pub/code/inv/index.html
